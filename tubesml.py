# -*- coding: utf-8 -*-
"""tubesML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sW8wMrG6nCd4DMIPSKVyHKhYoOCO65X6

# Persiapan Data
"""

import math
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from pandas import DataFrame
import numpy as np
import seaborn as sns
sns.set(style="darkgrid")


url = 'https://raw.githubusercontent.com/edinugroho/Final-Task-Machine-Learning/master/used_cars.csv'
used_cars = pd.read_csv(url)

used_cars.region = pd.factorize(used_cars.region)[0]
used_cars.url = pd.factorize(used_cars.url)[0]
used_cars.region_url = pd.factorize(used_cars.region_url)[0]
used_cars.manufacturer = pd.factorize(used_cars.manufacturer)[0]
used_cars.model = pd.factorize(used_cars.model)[0]
used_cars.year = pd.factorize(used_cars.year)[0]
used_cars.condition = pd.factorize(used_cars.condition)[0]
used_cars.cylinders = pd.factorize(used_cars.cylinders)[0]
used_cars.odometer = pd.factorize(used_cars.odometer)[0]
used_cars.title_status = pd.factorize(used_cars.title_status)[0]
used_cars.transmission = pd.factorize(used_cars.transmission)[0]
used_cars.vin = pd.factorize(used_cars.vin)[0]
used_cars.model = pd.factorize(used_cars.model)[0]
used_cars.image_url = pd.factorize(used_cars.image_url)[0]
used_cars.lat = pd.factorize(used_cars.lat)[0]
used_cars.drive = pd.factorize(used_cars.drive)[0]
used_cars['long'] = pd.factorize(used_cars['long'])[0]
used_cars['size'] = pd.factorize(used_cars['size'])[0]
used_cars['type'] = pd.factorize(used_cars['type'])[0]
used_cars['paint_color'] = pd.factorize(used_cars['paint_color'])[0]
used_cars['description'] = pd.factorize(used_cars['description'])[0]
used_cars['county'] = pd.factorize(used_cars['county'])[0]
used_cars['state'] = pd.factorize(used_cars['state'])[0]

used_cars.fuel.unique()

#save file
used_cars.to_csv('clean-data.csv')

"""# Featue engineering"""

import math
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from pandas import DataFrame
import numpy as np
import seaborn as sns
used_cars = pd.read_csv('clean-data.csv', index_col=False)
used_cars.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1, inplace=True)

data_mean=used_cars.iloc[:,1:20]

corr = data_mean.corr()
# Generate a mask for the upper triangle
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

# Set up the matplotlib figure
data, ax = plt.subplots(figsize=(20, 20))
plt.title('Fuel Feature Correlation')

# Generate colormap
cmap = sns.diverging_palette(260, 10, as_cmap=True)

# membuat heatmap
sns.heatmap(corr, vmax=1.2, square='square', cmap=cmap, mask=mask, 
            ax=ax,annot=True, fmt='.2g',linewidths=1)

plt.style.use('fivethirtyeight')
sns.set_style("dark")
used_cars = pd.read_csv('clean-data.csv',usecols=['fuel','transmission','type'], index_col=False)
# used_cars.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1, inplace=True)
used_cars
# used_carsn = used_cars['fuel'],used_cars['type'],used_cars['transmission']
g = sns.PairGrid(used_cars, hue='fuel')
g = g.map_diag(plt.hist)
g = g.map_offdiag(plt.scatter, s = 3)

"""# Pre Processing"""

used_cars = pd.read_csv('clean-data.csv',usecols=['fuel','transmission','type'], index_col=False)
used_cars.dropna(inplace=True)
X = used_cars.drop(['fuel'], axis = 1)
y = used_cars['fuel']

"""MEMBUAT DATA TEST DAN DATA TRAIN"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)
print ('The size of our training "X" (input features) is', X_train.shape)
print ('The size of our testing "X" (input features) is', X_test.shape)
print ('The size of our training "y" (output feature) is', y_train.shape)
print ('The size of our testing "y" (output features) is', y_test.shape)

from sklearn.preprocessing import StandardScaler
# Normalisasi.
scaler =StandardScaler()
Xs = scaler.fit_transform(X)

from sklearn.decomposition import PCA
# feature extraction
pca = PCA(n_components=2)
fit = pca.fit(Xs)

X_pca = pca.transform(Xs)

PCA_df = pd.DataFrame()

PCA_df['PCA_1'] = X_pca[:,0]
PCA_df['PCA_2'] = X_pca[:,1]

plt.plot(PCA_df['PCA_1'][used_cars.fuel == 'gas'],PCA_df['PCA_2'][used_cars.fuel == 'gas'],'o', alpha = 0.7, color = 'r')
plt.plot(PCA_df['PCA_1'][used_cars.fuel == 'diesel'],PCA_df['PCA_2'][used_cars.fuel == 'diesel'],'o', alpha = 0.7, color = 'b')

plt.xlabel('PCA_1')
plt.ylabel('PCA_2')
plt.legend(['Gas','Diesel'])
plt.show()

"""# SVM"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svc_model = SVC()
svc_model.fit(X_train, y_train)
y_predict = svc_model.predict(X_test)
print(classification_report(y_test, y_predict))

"""# KNN"""

from sklearn.neighbors import KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=3)
neigh.fit(X_train,y_train)
y_predict = neigh.predict(X_test)
accuracy_score(y_test,y_predict)
print(classification_report(y_test, y_predict))